# SpeechFeedback

End-to-End ASR (Automatic Speech Recognition) Feedback System

**IPA ë³€í™˜**ì„ í†µí•˜ì—¬ ë°œìŒ ê·¸ëŒ€ë¡œ ì¸ì‹í•˜ë„ë¡ í•˜ê³  ê·¸ì— ëŒ€í•œ **ë°œìŒ í”¼ë“œë°±**ì„ ì§„í–‰í•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ê²ƒì´ ëª©í‘œì´ë‹¤.

KoSpeech íˆ´í‚· : [sooftware/kospeech](https://github.com/sooftware/kospeech) ì„ í™œìš©í•˜ì—¬ í”„ë¡œì íŠ¸ë¥¼ ì§„í–‰í•˜ì˜€ë‹¤.

Baidu Research â€“ Silicon Valley AI Lab, [*Deep Speech 2: End-to-End Speech Recognition in English and Mandarin*](https://arxiv.org/pdf/1512.02595v1.pdf), Computation and Language, Dec 2015
  - ë‹¤ìŒ ë…¼ë¬¸ì—ì„œì˜ ëª¨ë¸ êµ¬ì¡°ë¥¼ ì°¸ê³ í•˜ì˜€ìŠµë‹ˆë‹¤.

ì¥ë¯¼ì •, ì •ì„ ì§„, ë…¸ì¤€ìš©, [*í•œêµ­ì–´ ë™ì‹œì¡°ìŒ ëª¨ë¸ì— ê¸°ë°˜í•œ ìŠ¤í”¼ì¹˜ ì• ë‹ˆë©”ì´ì…˜ ìƒì„±*](http://journal.cg-korea.org/archive/view_article?pid=jkcgs-26-3-49), ì»´í“¨í„°ê·¸ë˜í”½ìŠ¤í•™íšŒ, Jun 2020
  - ë‹¤ìŒ ë…¼ë¬¸ì—ì„œì˜ í˜€ ëª¨ë¸ ì‹œê° ìë£Œë¥¼ í™œìš©í•˜ì˜€ìŠµë‹ˆë‹¤.

<br/>

### Contents
0. [Folder Structure](#folder-structure)
1. [Environment Setting](#environment-setting)
2. [Docker Image](#docker-image)
3. [How to done Preprocessing (IPA and Character Dictionary)](#how-to-done-preprocessing-ipa-and-character-dictionary)
4. [Model Architecture](#model-architecture)
5. [How to train Deep Speech 2 model](#how-to-train-deep-speech-2-model)
6. [How to evaluate Deep Speech 2 model](#how-to-evaluate-deep-speech-2-model)
7. [How to inference the audio file using Deep Speech 2 model](#how-to-inference-the-audio-file-using-deep-speech-2-model)
8. [Performance After Using IPA](#performance-after-using-ipa)
9. [ETC](#etc)

<br/>

-----

### Folder Structure

```
ğŸ“¦SpeechFeedback
 â”£ ğŸ“‚docs
 â”£ ğŸ“‚feedback       // ìŒì„± í”¼ë“œë°± ê¸°ëŠ¥ ì‹œì—°ì„ ìœ„í•œ í´ë¼ì´ì–¸íŠ¸ ì½”ë“œ
 â”£ ğŸ“‚kospeech
 â”ƒ â”£ ğŸ“‚bin          // ëª¨ë¸ í•™ìŠµ, í‰ê°€, ì¶”ë¡  í•¨ìˆ˜ê°€ ìˆìŒ. FastAPI ì„œë²„ë¡œ ìŒì„± í”¼ë“œë°± ì •ë³´ ì œê³µ.
 â”ƒ â”£ ğŸ“‚configs      // ëª¨ë¸ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •
 â”ƒ â”£ ğŸ“‚dataset
 â”ƒ â”ƒ â”— ğŸ“‚kspon      // ë°ì´í„°ì…‹ì— ëŒ€í•œ ì „ì²˜ë¦¬ ì‘ì—…ê³µê°„
 â”ƒ â”£ ğŸ“‚docs
 â”ƒ â”£ ğŸ“‚kospeech
 â”ƒ â”— ğŸ“‚test
 â”£ ğŸ“‚preprocess     // ë°ì´í„° ì „ì²˜ë¦¬ë¥¼ ìœ„í•œ ì½”ë“œ ê¾¸ëŸ¬ë¯¸ (kospeech í´ë”ì—ëŠ” ì´ë¯¸ ë°˜ì˜ë¨)
 â”— ğŸ“‚data           // í•´ë‹¹ ë””ë ‰í† ë¦¬ì— KsponSpeech ë°ì´í„°ì…‹ ë‹¤ìš´
```

<br/>

### Environment Setting

- ì‹¤í—˜ í™˜ê²½
  - Docker Image : [devtae/kospeech](https://hub.docker.com/r/devtae/kospeech)
  - OS : Linux 5.4.0-148-generic x86_64
  - CPU : 12th Gen Intel(R) Core(TM) i9-12900K
  - GPU : (NVIDIA GeForce RTX 4090 24GB) X 2
  - CUDA version : 12.0
  - PyTorch version : 1.9.0+cu111

<br/>

### Docker Image

KoSpeech (Using CUDA 12.0) : https://hub.docker.com/r/devtae/kospeech

1. `sudo docker run -it --gpus all --name devtae -v {í•˜ìœ„ ë””ë ‰í† ë¦¬}/í•œêµ­ì–´\ ìŒì„±:/workspace/data devtae/kospeech`
    - ê³µìœ  ë””ë ‰í† ë¦¬ ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ì—¬, `{í•˜ìœ„ ë””ë ‰í† ë¦¬}/í•œêµ­ì–´\ ìŒì„±` í´ë”ì— ìˆëŠ” íŒŒì¼ë“¤ì´ `/workspace/data` ê³¼ ì—°ë™ëœë‹¤.
    - ì›í™œí•œ ê³µìœ  ë””ë ‰í† ë¦¬ ì„¤ì •ì„ ìœ„í•˜ì—¬ ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ í›„ì— ìˆ˜í–‰í•˜ëŠ” ê²ƒì„ ì¶”ì²œí•œë‹¤.

2. `sudo docker attach devtae` ë¥¼ ì‹¤í–‰í•œ ë’¤, Docker ì´ë¯¸ì§€ ë‚´ì—ì„œ ì‘ì—…í•œë‹¤.

3. í˜„ì¬ ë ˆí¬ë¥¼ `clone` í•˜ì—¬ kospeech í´ë”ë¥¼ workspace í´ë” ì•ˆì— ë„£ê³  ì‘ì—…ì„ ì§„í–‰í•œë‹¤.

<br/>

### How to done Preprocessing (IPA and Character Dictionary)

- ìŒì„± ë°ì´í„° ìˆ˜ì§‘ ë° ì „ì²˜ë¦¬
  - ë°ì´í„°ì…‹ : [AIHub í•œêµ­ì–´ ìŒì„±](https://aihub.or.kr/aihubdata/data/view.do?currMenu=115&topMenu=100&aihubDataSe=realm&dataSetSn=123)
  - IPA ë³€í™˜ê¸° : [í‘œì¤€ë°œìŒ ë³€í™˜ê¸°](http://pronunciation.cs.pusan.ac.kr/)
  - IPA ë³€í™˜ê¸° : [stannam/hangul_to_ipa](https://github.com/stannam/hangul_to_ipa)
  - ì „ì²´ ë°ì´í„°ì— ëŒ€í•˜ì—¬ ë‹¤ìŒê³¼ ê°™ì´ í•™ìŠµì„ ì§„í–‰í•˜ì˜€ìŒ
    - `Training : Validation : Test = 600000 : 10000 : 10000`

1. `cd SpeechFeedback/kospeech/dataset/kspon` í›„ì— `bash preprocess.sh` ë¥¼ ì‹¤í–‰í•˜ì—¬ ì „ì²˜ë¦¬ë¥¼ ì§„í–‰í•œë‹¤.

2. ê·¸ ê²°ê³¼, `SpeechFeedback/kospeech/dataset/kspon` ë””ë ‰í† ë¦¬ì— `transcripts.txt` ì™€ ë‹¨ì–´ ì‚¬ì „ì¸ `aihub_labels.csv` ê°€ ì €ì¥ëœë‹¤.

- í•´ë‹¹ ë ˆí¬ì— ìˆëŠ” ì½”ë“œëŠ” Training ë°ì´í„°ì— ëŒ€í•´ì„œë§Œ ì „ì²˜ë¦¬í•˜ëŠ” ê²ƒì´ë©°, Evaluation ë°ì´í„°ë¥¼ ì´ìš©í•˜ì§€ ì•ŠëŠ”ë‹¤. ë”°ë¼ì„œ ë³„ ë‹¤ë¥¸ ìˆ˜ì • ì—†ì´ ì‚¬ìš©í•œë‹¤ë©´, Training ì—ì„œ ì›í•˜ëŠ” ë°ì´í„°ë“¤ì„ ë°”íƒ•ìœ¼ë¡œ transcripts ë¥¼ í˜•ì„±ì‹œí‚¤ê³ , ê·¸ ì¤‘ì—ì„œë„ ì¼ë¶€ë¥¼ ë–¼ì–´ë‚´ ë”°ë¡œ evaluation ìš© `transcripts_test.txt` íŒŒì¼ì„ ë§Œë“¤ì–´ ì‚¬ìš©í•˜ë©´ ëœë‹¤.

<br/>

### Model Architecture

- `Deep Speech 2` ëª¨ë¸ êµ¬ì¡°
  - **3-Layer CNN**
    - [ë‹¤ìŒ ë§í¬](https://github.com/DevTae/SpeechFeedback/blob/main/docs/how-to-change-into-3-layer-cnn.md)ì˜ ë©”ë‰´ì–¼ì„ ë°”íƒ•ìœ¼ë¡œ 2-Layer CNN ì—ì„œ 3-Layer CNN ìœ¼ë¡œ ìˆ˜ì •í•  ìˆ˜ ìˆìŒ
  - Bi-directional GRU Layer x 7
    - RNN ë ˆì´ì–´ ìˆ˜ëŠ” í•˜ì´í¼ íŒŒë¼ë¯¸í„° íŠœë‹ì—ì„œ ì„¤ì • ê°€ëŠ¥
  - Fully Connected Layer x 1
  - Batch Normalization
    - ëª¨ë“  ë ˆì´ì–´ì— momentum=0.99 ìœ¼ë¡œ ì„¤ì •
  - CTC Loss
  - **í˜„ì¬ ì €ì¥ì†Œì—ëŠ” 2-Layer CNN + Bi-directional GRU Layer x 3 ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŒ**

- [í•˜ì´í¼ íŒŒë¼ë¯¸í„° íŠœë‹](https://github.com/DevTae/SpeechFeedback/blob/main/docs/hyper-parameter-tuning.md)
  - Baidu Deep Speech 2 Paper ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•˜ì´í¼ íŒŒë¼ë¯¸í„° íŠœë‹ì„ ì§„í–‰í•¨.

<br/>

### How to train `Deep Speech 2` model

1. `KoSpeech/kospeech/data/data_loader.py` ì—ì„œ train, validation ë°ì´í„° ìˆ˜ë¥¼ ì„¤ì •í•œë‹¤. (transcripts.txt íŒŒì¼ì—ì„œì˜ ë°ì´í„° ìˆ˜)
    - ë§Œì•½ train : validation : test ë¹„ìœ¨ì„ ì„¤ì •í•˜ê³ ì í•  ë•ŒëŠ”, train+validation ë§Œí¼ transcripts.txt ì— ìˆë„ë¡ í•˜ê³ , ë‚˜ë¨¸ì§€ test ë§Œí¼ transcripts_test.txt ì— ìˆë„ë¡ í•œë‹¤.
    - train ê³¼ validation ë°ì´í„° ê°œìˆ˜ëŠ” data_loader.py ì—ì„œ ì„¤ì •í•œë‹¤.

2. `python ./bin/main.py model=ds2 train=ds2_train train.dataset_path=/workspace/data` ë¥¼ ì‹¤í–‰í•œë‹¤.

- (optional) CTC Loss ê³„ì‚°ì‹ì—ì„œ nan ì´ ëœ¨ëŠ” ê²ƒì„ ë°©ì§€í•˜ê³  ì‹¶ë‹¤ë©´ **ë°ì´í„° ë³´ì •** ë° **í•˜ì´í¼ íŒŒë¼ë¯¸í„° ìˆ˜ì •**ì„ í•˜ê±°ë‚˜ `torch.nan_to_num(outputs)` í•¨ìˆ˜ë¥¼ ì´ìš©í•œë‹¤.
  - `torch.nan_to_num(outputs)` ì˜ ê²½ìš°, ë‹¤ìŒ ì½”ë“œì™€ ê°™ì´ ë°”ê¾¸ë©´ ëœë‹¤.
  ```Python
  # in kospeech/kospeech/trainer/supervised_learning.py:454L
  ...
  elif architecture in ('deepspeech2', 'jasper'):
      outputs, output_lengths = model(inputs, input_lengths)
      outputs = torch.nan_to_num(outputs)
      loss = self.criterion(
          outputs, targets[:, 1:], contiguous().int(), input_lengths.int(), target_lengths.int()
      )
  ...
  ```

<br/>

### How to evaluate `Deep Speech 2` model

- ì•„ë˜ ì½”ë“œë¥¼ ë°”íƒ•ìœ¼ë¡œ í‰ê°€ë¥¼ ì§„í–‰í•œë‹¤.

- `python ./bin/eval.py eval.dataset_path=/workspace/data eval.transcripts_path=/workspace/kospeech/dataset/kspon/transcripts_test.txt eval.model_path=/workspace/kospeech/outputs/{date}/{time}/model.pt`
  - `Beam Search` ì§„í–‰
  - [parlance/ctcdecode](https://github.com/parlance/ctcdecode)

<br/>

### How to inference the audio file using `Deep Speech 2` model

- ì•„ë˜ ì½”ë“œë¥¼ ë°”íƒ•ìœ¼ë¡œ í•´ë‹¹ ì˜¤ë””ì˜¤ íŒŒì¼ì— ëŒ€í•˜ì—¬ ì¶”ë¡ ì„ í•œë‹¤.

- `python3 ./bin/inference.py --model_path /workspace/kospeech/outputs/{date}/{time}/model.pt --audio_path /workspace/data/{sub_path}/{audio_file}.wav --device "cpu"`

<br/>

### Performance After Using IPA

![23 6 25 aihub_labels csv](https://github.com/DevTae/SpeechFeedback/assets/55177359/b93e5eaa-7af4-44b2-a7df-50eef182b9ab)

- ë‹¨ì–´ì‚¬ì „ ê²½ìš°ì˜ ìˆ˜(ì¶œë ¥ì¸µ)ë¥¼ **2000 â†’ 41 ê°œ**ë¡œ ì¶•ì†Œí•  ìˆ˜ ìˆì—ˆë‹¤.
- IPA ë¬¸ì í˜•íƒœì— ë§ê²Œ ìµœì†Œ ë‹¨ìœ„ë¡œ ë‚˜ë‰  ìˆ˜ ìˆë„ë¡ ì „ì²˜ë¦¬ ì§„í–‰í•˜ì˜€ë‹¤.

![image](https://github.com/DevTae/SpeechFeedback/assets/55177359/01b6e492-6ed4-41a4-adce-0948069db9de)

![23 6 20 Feedback GUI System](https://github.com/DevTae/SpeechFeedback/assets/55177359/70ec3eba-7337-4143-9a94-0700fc92fd61)

- **í”¼ë“œë°± ì•Œê³ ë¦¬ì¦˜**ì„ ì ìš©í•˜ì—¬ [ë°œìŒì— ëŒ€í•œ í”¼ë“œë°±](https://github.com/DevTae/SpeechFeedback/tree/main/feedback)ì„ ì œê³µí•  ìˆ˜ ìˆê²Œ ë˜ì—ˆë‹¤.

<br/>

### ETC

#### ë°ì´í„° ì¢…ë¥˜ì— ë”°ë¥¸ ì„±ëŠ¥ ê°œì„ 
  - ì›ë³¸ ë°ì´í„°ë¥¼ ì§ì ‘ ë“¤ì–´ë³¸ ê²°ê³¼, ê°•ì˜ì˜ ì˜¤ë””ì˜¤ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë§Œë“  ë°ì´í„°ì…‹ìœ¼ë¡œ ì¡ìŒ ë° ì˜¤ë””ì˜¤ì˜ ì „ì²´ì ì¸ í†¤ì´ ë†’ì•˜ë‹¤.
  - ë”°ë¼ì„œ, [í•œêµ­ì¸ ëŒ€í™”ìŒì„±](https://aihub.or.kr/aihubdata/data/view.do?currMenu=115&topMenu=100&aihubDataSe=realm&dataSetSn=130)ì—ì„œ [í•œêµ­ì–´ ìŒì„±](https://aihub.or.kr/aihubdata/data/view.do?currMenu=115&topMenu=100&aihubDataSe=realm&dataSetSn=123)ìœ¼ë¡œ ë°”ê¾¼ ê²°ê³¼, ì˜¤ë””ì˜¤ê°€ ì¼ë°˜ì¸ ëŒ€í™”ì— ì ìš©í•˜ê¸°ì— ë”ìš± ì í•©í•¨ì„ í™•ì¸í•  ìˆ˜ ìˆì—ˆë‹¤.

#### ë°ì´í„° ë¼ë²¨ë§ ê°œìˆ˜ ì¶”ê°€ í™•ë³´ì— ë”°ë¥¸ ì„±ëŠ¥ ê°œì„ 
  - ì´ì „ì—ëŠ” í‘œì¤€ë°œìŒ ë³€í™˜ê¸° ì‚¬ì´íŠ¸ì—ì„œ ë°ì´í„° ìˆ˜ì§‘ì„ ì§„í–‰í•˜ì˜€ëŠ”ë°, ì‚¬ì´íŠ¸ íŠ¸ë˜í”½ ë¬¸ì œë¡œ ì•½ 1 ë§Œ ê°œì˜ ë°ì´í„° ë°–ì— í›ˆë ¨ì— ì ìš©í•  ìˆ˜ ì—†ëŠ” ìƒíƒœì˜€ë‹¤.
  - ë”°ë¼ì„œ, 1 epoch ì— ëŒ€í•˜ì—¬ í•™ìŠµë˜ëŠ” ì–‘(batch_size=32 ê¸°ì¤€ìœ¼ë¡œ step size ê°€ `625 ê°œ`)ì´ ì ì—ˆë‹¤.
  - GitHub ì— publish ëœ R ì½”ë“œ([stannam/hangul_to_ipa](https://github.com/stannam/hangul_to_ipa))ë¥¼ ë°”íƒ•ìœ¼ë¡œ IPA ë³€í™˜í•´ì£¼ëŠ” íŒŒì´ì¬ ìŠ¤í¬ë¦½íŠ¸ë¡œ ë³€í™˜í•˜ì˜€ê³  ë°ì´í„° ìˆ˜ë¥¼ `1 ë§Œ ê°œ`ì—ì„œ `60 ë§Œ ê°œ`ê¹Œì§€ ëŠ˜ë¦´ ìˆ˜ ìˆì—ˆë‹¤.
  - ê·¸ ê²°ê³¼ 1 epoch ì— ëŒ€í•œ step size ê°€ `37500 ê°œ`ë¡œ ì•½ 60ë°° ì»¤ì¡Œê³  ë™ì¼ epoch ì— ëŒ€í•˜ì—¬ CER ì´ í–¥ìƒë  ìˆ˜ ìˆì—ˆë‹¤.

#### CNN ë° RNN ë ˆì´ì–´ ìˆ˜ ìƒìŠ¹ì„ í†µí•œ ì„±ëŠ¥ ê°œì„ 
  - Deep Speech 2 ë…¼ë¬¸ì— ìˆëŠ” ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ëª¨ë¸ êµ¬ì¡°ë¥¼ ì ìš©í•˜ê³ ì í•˜ì˜€ëŠ”ë°, KoSpeech ì˜ ê¸°ë³¸ êµ¬ì¡°ëŠ” `CNN * 2, RNN * 3` ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆì—ˆë‹¤.
  - Baidu ì˜ Deep Speech 2 ë…¼ë¬¸ì— ë”°ë¥´ë©´ `CNN * 3, RNN * 7` ê°€ ì„±ëŠ¥ì´ ì¢‹ë‹¤ëŠ” ê²ƒì„ ì°¾ì„ ìˆ˜ ìˆì—ˆë‹¤.
  - ë°œìŒ í”¼ë“œë°± ì‹œìŠ¤í…œ ì ìš©ì„ ìœ„í•˜ì—¬ ì‹¬ì¸µì ì¸ ëª¨ë¸ì´ í•„ìš”í•˜ë‹¤ê³  íŒë‹¨í•˜ì˜€ê³ , ì´ë¥¼ ì ìš©í•˜ê¸° ìœ„í•´ [ì½”ë“œë¥¼ ìˆ˜ì •](https://github.com/DevTae/SpeechFeedback/blob/main/docs/3-Layer-CNN.md)í•  ìˆ˜ ìˆì—ˆë‹¤.
  - ê·¸ ëŒ€ì‹ , ë ˆì´ì–´ê°€ ê²¹ì³ì§ˆìˆ˜ë¡ ëª¨ë¸ì˜ ë³µì¡ì„±ì´ ì˜¬ë¼ê°€ í•™ìŠµ ì†ë„ê°€ í˜„ì €íˆ ëŠë ¤ì§€ë¯€ë¡œ í•´ë‹¹ trade-off ê´€ê³„ì—ì„œ ì ë‹¹í•œ ì„¤ì •ìœ¼ë¡œ ì ‘ê·¼í•˜ê³ ì í•˜ì˜€ë‹¤.

#### momentum ê³„ìˆ˜ ìˆ˜ì •ì„ í†µí•œ í•™ìŠµ ì„±ëŠ¥ ê°œì„ 
  - Deep Speech 2 ë…¼ë¬¸ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ëª¨ë“  BatchNorm ì— ëŒ€í•˜ì—¬ momentum ê³„ìˆ˜ë¥¼ 0.99 ìœ¼ë¡œ ì ìš©í•˜ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆì—ˆë‹¤.
  - í•˜ì§€ë§Œ, KoSpeech ì˜ momentum ê³„ìˆ˜ ê¸°ë³¸ ì„¤ì •ì€ 0.1 ì´ì—ˆê³ , ì´ì— ë”°ë¼, ëª¨ë“  BatchNorm ì— ëŒ€í•˜ì—¬ momentum ê³„ìˆ˜ì— 0.99 ë¥¼ ì ìš©í•  ìˆ˜ ìˆì—ˆë‹¤.
  - ì´ëŸ¬í•œ ê²°ê³¼ë¡œ ê¸°ìš¸ê¸°ì— ì´ì „ ê´€ì„±ì´ ì ìš©ë˜ì–´ `local minima í˜„ìƒì„ ì–µì œ`í•  ìˆ˜ ìˆì—ˆìœ¼ë©° `CER ê°ì†Œ ì¶”ì„¸ê°€ ë³´ë‹¤ linear í•˜ê²Œ` ë°”ë€ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆì—ˆë‹¤.

#### warmup step ì„¤ì •ì„ í†µí•œ local minima í˜„ìƒ ê°œì„ 

![image](https://github.com/DevTae/SpeechFeedback/assets/55177359/7da12595-4393-495b-8c3e-e8d1487f9f63)

(ì‚¬ì§„ ì¶œì²˜ : [sooftware/pytorch-lr-scheduler](https://github.com/sooftware/pytorch-lr-scheduler))

  - adam optimizer ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•œ í•™ìŠµ ì´ˆë°˜ì—ëŠ” local minima ê°€ ë°œìƒí•  í™•ë¥ ì´ ë†’ë‹¤.
  - ì´ëŸ¬í•œ ì´ìœ ë¡œ KoSpeech ì—ì„œëŠ” í•™ìŠµ ì´ˆë°˜ì˜ learning rate ë¥¼ ì¡°ì ˆí•˜ëŠ” warmup step ë°©ì‹ì¸ TriStageLRSchedule ë¥¼ ì ìš©í•˜ì˜€ë‹¤.
  - TriStageLRSchedule ìŠ¤ì¼€ì¤„ëŸ¬ ì•Œê³ ë¦¬ì¦˜ì˜ ì½”ë“œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì „ì²´ í•™ìŠµì— ëŒ€í•˜ì—¬ `ì²˜ìŒë¶€í„° ì •í•´ì§„ ë‹¨ê³„ë§Œí¼ warmup` ì„ í•˜ê³  `ì ˆë°˜ê¹Œì§€ ìµœëŒ“ê°’ì„ ìœ ì§€`í–ˆë‹¤ê°€ `ì´í›„ë¶€í„°ëŠ” learning rate ê°€ ê°ì†Œ`í•˜ëŠ” ë°©ì‹ì„ì„ ì•Œ ìˆ˜ ìˆì—ˆë‹¤.
  - í•´ë‹¹ ìŠ¤ì¼€ì¤„ëŸ¬ì˜ warmup ì„¤ì • ê´€ì ì„ ë³´ì•„í•˜ë‹ˆ ì ì–´ë„ ì „ì²´ step size ì˜ `10%`(=75000)ë§Œí¼ì€ warmup step ìœ¼ë¡œ ì„¤ì •í•´ì•¼ê² ìŒì„ ëŠê¼ˆê³  ì´ë¥¼ ì ìš©í•´ë³´ì•˜ë‹¤.
  - ê·¸ ê²°ê³¼, ì´ì „(=400)ì— ëŒ€ë¹„í•˜ì—¬ í•™ìŠµ ì´ˆë°˜ë¶€í„° ë†’ì€ lossì™€ CER ê°’ì— ìˆ˜ë ´í•˜ëŠ” local minima ë¥¼ ê°œì„ í•  ìˆ˜ ìˆì—ˆë‹¤.

#### í•™ìŠµ ì¤‘ ë¬´í•œ ë¡œë”©(in threading queue)ì´ ê±¸ë¦¬ëŠ” í˜„ìƒ í•´ê²°
  - ëŒ€ìš©ëŸ‰ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•™ìŠµ ì¤‘ `kospeech/kospeech/trainer/supervised_trainer.py` ì˜ `queue.get()` ì—ì„œ ë¬´í•œ ë¡œë”©ì´ ê±¸ë¦¬ê²Œ ëœë‹¤.
  - ì´ëŸ° ê²½ìš°ì— ëŒ€í•˜ì—¬ ë°ë“œë½ì´ ì£¼ìš”í•œ ì›ì¸ì´ë¼ê³  íŒë‹¨ ì¤‘ì´ë‹¤. ê·¸ ì´ìœ ëŠ” í•´ë‹¹ epoch ë‚´ì— í•™ìŠµí•  ë°ì´í„° ìˆ˜ëŠ” ë‚¨ì•„ìˆì§€ë§Œ, queue ì— ëŒ€í•œ get í•¨ìˆ˜ì—ì„œ ë¬´í•œëŒ€ê¸°ë¥¼ í•˜ê¸° ë•Œë¬¸ì´ë‹¤.
  - ë”°ë¼ì„œ, í•´ë‹¹ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ queue ì— ëŒ€í•˜ì—¬ ë™ê¸°ì ìœ¼ë¡œ ì ‘ê·¼ í›„ ê¸°ë‹¤ë¦¬ëŠ” `get` í•¨ìˆ˜ê°€ ì•„ë‹Œ queue ì˜ ì›ì†Œê°€ ì—†ìœ¼ë©´ ë°”ë¡œ exception raise í•˜ëŠ” `get_nowait()` í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ í•´ê²°í•˜ì˜€ë‹¤.
  - ì´ì— ëŒ€í•œ ìì„¸í•œ í•´ê²° ë°©ë²•ì€ í•´ë‹¹ [ë§í¬](https://github.com/DevTae/SpeechFeedback/blob/main/docs/how-to-solve-the-infinity-loading.md)ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆë‹¤.
